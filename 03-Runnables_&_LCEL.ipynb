{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc52a70d-9f16-4dc3-ba61-49691c4a6c1f",
   "metadata": {},
   "source": [
    "### Runnable\n",
    "\n",
    "**Runnable in LangChain is a class** that serves as a base abstraction representing a unit of work that can be invoked, batched, streamed, transformed, and composed\n",
    "It provides a standardized interface to run chains of operations where the output of one step can be fed as input to the next, allowing for simple, linear, or more complex workflows to be built and executed efficiently.\n",
    "\n",
    "Primitives and utilities provided for working with Runnables include:\n",
    "\n",
    "- **`pipe`** (or **`|`** operator) to chain Runnables sequentially\n",
    "- **`fromMap`** to run multiple Runnables concurrently on the same input\n",
    "- **`passthrough`** to pass input as output\n",
    "- **`mapInput`** and **`mapInputStream`** to transform inputs or streams\n",
    "- **`fromFunction`** to wrap arbitrary functions as Runnables\n",
    "- **`fromRouter`** to route inputs dynamically to different Runnables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311b570e-2471-4fca-bd6b-bf766bad3eb8",
   "metadata": {},
   "source": [
    "### LangChain Expression Language (LCEL)\n",
    "LangChain Expression Language is a way to create arbitrary custom chains. It is built on the Runnable protocol. One point about LangChain Expression Language is that any two runnables can be \"chained\" together into sequences. The output of the previous runnable's `.invoke()` call is passed as input to the next runnable. This can be done using the pipe operator `(|)`, or the more explicit `.pipe()` method, which does the same thing.\n",
    "\n",
    "The resulting `RunnableSequence` is itself a runnable, which means it can be invoked, streamed, or further chained just like any other runnable.\n",
    "\n",
    "**When to use LCEL?** \n",
    "- If you are making a single LLM call, you don't need LCEL; instead call the underlying chat model directly.\n",
    "- If you have a simple chain (e.g., prompt + llm + parser, simple retrieval set up etc.), LCEL is a reasonable fit, if you're taking advantage of the LCEL benefits.\n",
    "- If you're building a complex chain (e.g., with branching, cycles, multiple agents, etc.) use LangGraph instead. Remember that you can always use LCEL within individual nodes in LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61869f0-6159-4c3e-be01-732aba3df664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
